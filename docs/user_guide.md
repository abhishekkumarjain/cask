% Spark User Guide

# Glossary

__Warning! This document is a work in progress. Until this notice is removed, please treat it as such__

Application code refers to the code using libraries generated by Spark.

# Basic Usage

## Compiling and Running Application Code

Application code is compiled and linked against the CPU interface mocks
provided. At runtime, Spark selects the optimal implementation from a number of
pre-optimised shared libraries. If not suitable library can be found an
exception is thrown.


## Running Benchmarking

Benchmarking is important to validate performance models.  Benchmarking is
different from typical usage, because it requires control over the loaded
implementation. In general, for maximum flexibility, disable the auto load
function and provide the shared library under test on `LD_PRELOAD` or
`LD_LIBRARY_PATH`.

Benchmarking can be done either:

1. in simulation -- useful to check the performance model corresponds correctly
   to the design. But simulation does not account for some underlying physical
   or logical performance aspects such as memory bandwidth, resource usage,
   stalls

2. in hardware -- ideally provides an accurate measurement of performance, but
   is expensive to perform; it is also sensitive to interference by other
   processes on the target machine


TODO
Benchmarking can be automated through `spark.py`. The following configurations
are available:

1. Best fit -- picks the best library for each matrix, this corresponds to
   typical usage
2. One to all -- picks one library and benchmarks it on all matrices; if a
   matrix is not supported by the library, an exception will be thrown
3. All to all -- Run each library, in turn on all benchmarks

TODO Data is collected in CSV format and plots can be generated from it.

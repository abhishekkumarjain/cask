import java.util.*;

import com.maxeler.maxcompiler.v2.kernelcompiler.*;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.KernelMath;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.*;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Count.*;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.memory.*;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.*;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.*;
import com.maxeler.maxcompiler.v2.utils.MathUtils;

import com.custom_computing_ic.dfe_snippets.utils.Reductions;
import com.custom_computing_ic.dfe_snippets.reductions.LogAddReduce;

class SpmvKernel extends Kernel {

  // N x N matrix, nnzs nonzeros
  //
  // load data for N cycles into cache
  // compute for N cycles
  // -- in the mean time load data for N cycles in double buffer
  // repeat
  //
  // Sources of inefficiency:
  // -- empty rows
  // -- port sharing cannot be used

  private final DFEVectorType<DFEVar> vtype, ivtype;
  private final int inputWidth;
  private final DFEType addressT;
  private final boolean dbg;

  private static final int fpL = 16;

  protected SpmvKernel(
      KernelParameters parameters,
      int inputWidth,
      int cacheSize,
      int indexWidth,
      int mantissaWidth,
      boolean dbg) {
    super(parameters);

    optimization.pushPipeliningFactor(0.5);
    optimization.pushDSPFactor(1);


    this.inputWidth = inputWidth;
    this.addressT = dfeUInt(MathUtils.bitsToAddress(cacheSize));
    this.dbg = dbg;

    vtype = new DFEVectorType<DFEVar> (dfeFloat(11, mantissaWidth), inputWidth);
    ivtype = new DFEVectorType<DFEVar> (dfeUInt(indexWidth), inputWidth);

    // TODO: remove prefetch from this kernel

    DFEVar vRomLoadEnable = io.input("loadEnabled", dfeBool());
    DFEVector<DFEVar> matrixValues = io.input("matrixValues", vtype, ~vRomLoadEnable);
    DFEVector<DFEVar> vectorValues = io.input("vectorValues", vtype, ~vRomLoadEnable);

    DFEVar result = Reductions.reduce(matrixValues * vectorValues);

    // --- Accumulation
    DFEVar rowFinished = io.input("rowFinished", dfeBool());
    DFEVar rowLength = io.input("rowLength", dfeUInt(32));
    DFEVar cycleCounter = io.input("cycleCounter", dfeUInt(32));
    DFEVar firstReadPosition = io.input("firstReadPosition", dfeUInt(32));

    // must disable input registering to use as flush trigger
    io.pushInputRegistering(false);
    DFEVar flushTrigger = io.input("flush", dfeBool());
    io.popInputRegistering();

    flush.afterTrigger(flushTrigger);

    DFEVar runLength = firstReadPosition + rowLength;
    DFEVar modulo = KernelMath.modulo(runLength, inputWidth);
    DFEVar quot = (runLength - modulo.cast(dfeUInt(32))) / inputWidth;

    DFEVar totalCycles = quot + (modulo === 0 ? constant.var(dfeUInt(32), 0) : 1);

    DFEVar carriedSum = dfeFloat(11, mantissaWidth).newInstance(this);
    DFEVar newSum = result + (cycleCounter < fpL ? 0 : carriedSum);
    carriedSum <== stream.offset(newSum, -fpL);

    DFEVar firstValidPartialSum = (totalCycles > fpL)? (totalCycles - fpL) : 0;
    DFEVar validPartialSums = (cycleCounter >= firstValidPartialSum);
    LogAddReduce r = new LogAddReduce(this,
        validPartialSums,
        rowFinished,
        newSum,
        dfeFloat(11, mantissaWidth),
        fpL);

    // TODO still need reduction step
    // TODO: remove prefetch
    DFEVar outputEnable = ~vRomLoadEnable & rowFinished;
    io.output("output", r.getOutput(), dfeFloat(11, mantissaWidth), outputEnable | flushTrigger);
    io.output("flushTriggerOut", flushTrigger, dfeBool(), outputEnable | flushTrigger);
    //flush.allowOutputBeforeFlush("output");
    //flush.allowOutputBeforeFlush("flushTriggerOut");

    // --- Debug
    if (dbg) {
        Params rowCounterParams = control.count.makeParams(32)
          .withEnable(rowFinished);
        DFEVar rowCounter = control.count.makeCounter(rowCounterParams).getCount();
/*      debug.simPrintf(
          rowLength !== 0,
          "Kernel -- row %d totalCycles %d, readenable %d, readmask %d rowFinished %d rowLength %d output: %f cycleCounter %d validPartialSums %d newSum %f firstRead %d",
          rowCounter, totalCycles, readEnable, readMask, rowFinished, rowLength, r.getOutput(), cycleCounter, validPartialSums, newSum, firstReadPosition);
      debug.simPrintf(rowLength !== 0 , " loadEnable %d loadAddress %d\n", vRomLoadEnable, loadAddress);
*/
      //debug.simPrintf("\n");
      //debug.simPrintf("Values: ");
      //for (int i = 0; i < inputWidth; i++)
        //debug.simPrintf("%f ", values[i]);
      //debug.simPrintf("Indices: ");
      //for (int i = 0; i < inputWidth; i++)
        //debug.simPrintf("%d ", colptr[i]);
      //debug.simPrintf("\n");
    }
  }

}

// This implements cache
//
class SpmvCacheKernel extends Kernel {

  private final DFEVectorType<DFEVar> vtype, ivtype;
  private final List<Memory<DFEVar>> vroms;
  private final int inputWidth;
  private final DFEType addressT;

  protected SpmvCacheKernel(KernelParameters parameters,
      int inputWidth,
      int cacheSize,
      int indexWidth,
      int mantissaWidth) {
    super(parameters);

    this.inputWidth = inputWidth;
    this.addressT = dfeUInt(MathUtils.bitsToAddress(cacheSize));

    // load entire vector or until cache is full
    int sizeBits = 32; // XXX may need to run for more cycles
    DFEVar vRomLoadEnable = io.input("loadEnabled_in", dfeBool());

    // must disable input registering to use as flush trigger
    io.pushInputRegistering(false);
    DFEVar flushTrigger = io.input("flush", dfeBool());
    io.popInputRegistering();

    flush.afterTrigger(flushTrigger);

    DFEVar vectorLoadCycles = io.scalarInput("vectorLoadCycles", dfeUInt(32));
    Params loadAddressParams = control.count.makeParams(sizeBits )
      .withMax(vectorLoadCycles)
      .withEnable(vRomLoadEnable);
    DFEVar loadAddress = control.count.makeCounter(loadAddressParams).getCount();


    vtype = new DFEVectorType<DFEVar> (dfeFloat(11, mantissaWidth), inputWidth);
    ivtype = new DFEVectorType<DFEVar> (dfeUInt(indexWidth), inputWidth);
    DFEVectorType<DFEVar> inputType = new DFEVectorType<DFEVar> (dfeUInt(96), inputWidth);

    DFEVar vectorValue = io.input("vromLoad", dfeFloat(11, mantissaWidth), vRomLoadEnable);
     //--- Cache allocation and control
    vroms = new ArrayList<Memory<DFEVar>>();
    for (int i = 0; i < inputWidth; i++) {
      Memory<DFEVar> vrom = mem.alloc(dfeFloat(11, mantissaWidth), cacheSize);
      vroms.add(vrom);
      vrom.write(
          loadAddress.cast(addressT),
          vectorValue,
          vRomLoadEnable);
    }

    // --- I/O
    DFEVar readEnable = io.input("readenable", dfeBool()) & ~vRomLoadEnable;
    DFEVar readMask = io.input("readmask", dfeUInt(inputWidth));

    DFEVector<DFEVar> indptrValues = io.input("indptr_values", inputType, readEnable);
    DFEVector<DFEVar> valuesVector = vtype.newInstance(this);
    DFEVector<DFEVar> indptrVector = ivtype.newInstance(this);
    for (int i = 0; i < inputWidth; i++) {
      indptrVector[i] <== indptrValues[i].slice(64, 32).cast(dfeUInt(32));
      valuesVector[i] <== indptrValues[i].slice(0, 64).cast(dfeFloat(11, 53));
    }

    //for (int i = 0; i < inputWidth; i++)
      //debug.simPrintf("%d ", indptrVector[i]);
    //debug.simPrintf("\n");

    //for (int i = 0; i < inputWidth; i++)
      //debug.simPrintf("%f ", valuesVector[i]);
    //debug.simPrintf("\n");

    DFEVector<DFEVar> matrixValues = selectValues(
        valuesVector,
        readMask);
    DFEVector<DFEVar> colptr = selectValues(
        indptrVector,
        readMask);
    DFEVector<DFEVar> vectorValues = resolveVectorReads(colptr);

    io.output("loadEnabled_out", vRomLoadEnable, dfeBool());
    io.output("matrixValues", matrixValues, vtype, ~vRomLoadEnable);
    io.output("vectorValues", vectorValues, vtype, ~vRomLoadEnable);
  }

  DFEVector<DFEVar> selectValues(
      DFEVector<DFEVar> in,
      DFEVar readMask) {
    DFEVector<DFEVar> out = in.getType().newInstance(this);
    for (int i = 0; i < in.getSize(); i++)
      out[i] <== readMask.slice(i) === 0 ?  0 : in[i];
    return out;
  }


  DFEVector<DFEVar> resolveVectorReads(DFEVector<DFEVar> reads) {
    DFEVector<DFEVar> out = vtype.newInstance(this);
    for (int i = 0; i < vroms.size(); i++)
      out[i] <== vroms.get(i).read(reads[i].cast(addressT));
    return out;
  }

}




// XXX for now we assume the matrix is smaller then max rows
// will have to implement an lmem design above this threshold
// using lmem wrapped above this thresholed may be feasilbe,
// see the DramAccumulator snippet in dfe-snippets
class SpmvReductionKernel extends Kernel {

  protected SpmvReductionKernel(KernelParameters parameters, int fpl, int maxRows) {
    super(parameters);

    DFEVar in = io.input("reductionIn", dfeFloat(11, 53));
    DFEVar n = io.scalarInput("nRows", dfeUInt(32));
    DFEVar totalCycles = io.scalarInput("totalCycles", dfeUInt(32));

    DFEVar cycles = control.count.simpleCounter(32);

    DFEVar sumCarried = dfeFloat(11, 53).newInstance(this);
    DFEVar sum = in + (cycles < n ? 0 : sumCarried);
    sumCarried <== stream.offset(sum, -(n.cast(dfeInt(32))), -maxRows, -(fpl + 2));

    // output on the last n cycles
    DFEVar outputEnable = totalCycles - cycles <= n;
    io.output("reductionOut", sum, dfeFloat(11, 53), outputEnable);
  }
}


// uses BRAM storage instead of stream offsets, allows us to skip
// empty rows to achieve better throughput on matrices with long
// sequences of empty rows (e.g. banded matrices)
class BramSpmvReductionKernel extends Kernel {

  protected BramSpmvReductionKernel(KernelParameters parameters, int fpl, int maxRows) {
    super(parameters);

    DFEVar in = io.input("reductionIn", dfeFloat(11, 53));
    DFEVar n = io.scalarInput("nRows", dfeUInt(32));
    DFEVar totalCycles = io.scalarInput("totalCycles", dfeUInt(32));
    DFEVar cycles = control.count.simpleCounter(32);

    io.pushInputRegistering(false);
    DFEVar flushTrigger = io.input("flush", dfeBool());
    io.popInputRegistering();

    flush.afterTrigger(flushTrigger);

    // internal buffer for accumulating partial sums
    Memory<DFEVar> memory = mem.alloc(dfeFloat(11, 53), maxRows);

    // when skipCount != 0, we are to skip skipCount rows (since they are empty)
    DFEVar skipCount = constant.var(dfeUInt(32), 0); //io.input("skipCount", dfeUInt(32));
    DFEVar skipEnable = skipCount !== 0;
    DFEVar addressInc = skipEnable ? skipCount : 1;

    // the element we are going to accumulate with
    // initially, all data in the BRAM should be 0, it doesn't matter what we read
    int offset = 1; // offset for integer add
    optimization.pushPipeliningFactor(0);
    DFEVar carriedReadAddress = dfeUInt(32).newInstance(this);
    DFEVar nextReadAddress = (cycles < offset ? cycles : carriedReadAddress) + addressInc;
    DFEVar wrappedNextReadAddress = nextReadAddress === n ? 0 : nextReadAddress;
    carriedReadAddress <== stream.offset(wrappedNextReadAddress, -offset);
    optimization.popPipeliningFactor();

    DFEVar readAddress = cycles < n ? cycles : carriedReadAddress;
    DFEVar castReadAddress = readAddress.cast(dfeUInt(MathUtils.bitsToAddress(maxRows)));
    DFEVar prevSum = cycles < n ? 0 : memory.read(castReadAddress);
    DFEVar sum = prevSum + in;

    //debug.simPrintf(
        //"readAddress %d sum %f in %f\n",
        //readAddress, sum, in);

    Stream.OffsetExpr off = stream.measureDistance("BramAccOffset", readAddress, sum);
    memory.write(
        stream.offset(castReadAddress, -off),
        stream.offset(sum, -off),
        stream.offset(~skipEnable, -off));

    //debug.simPrintf("Reduction Kernel --> cycles %d flush: %d\n", cycles, flushTrigger);

    // output on the last n cycles
    DFEVar outputEnable = totalCycles - cycles <= n;
    io.output("reductionOut", sum, dfeFloat(11, 53), outputEnable);
  }
}

class PaddingKernel extends Kernel {
  protected PaddingKernel(KernelParameters parameters) {
    super(parameters);
    DFEVar nInputs = io.scalarInput("nInputs", dfeUInt(32));
    DFEVar cycles = control.count.simpleCounter(32);
    DFEVar paddingCycles = cycles >= nInputs;
    DFEVar input = io.input("paddingIn", dfeFloat(11, 53), ~paddingCycles);
    DFEVar out = paddingCycles ? 0 : input;
    io.output("paddingOut", out, dfeFloat(11, 53));
  }
}
